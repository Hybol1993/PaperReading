An Analysis of Linux Scalability to Many Cores 阅读报告
============

<center>毛海宇 2015310607 </center>
-----------------------------------------------------

##背景##
####why need to do####

####how previous research do####

####the main contribution of this paper####
>1. 一组名为MOSBENCH的benchmark，用来评测操作系统的可扩展性
>2. 16个对Linux 2.6.35-rc5 kernel的改善，命名为PK(patched kernel)
>3. 描述改善MOSBENCH中应用的可扩展性的必要技术

最终的结论：没有直接的因为可扩展性而放弃传统内核设计的理由

##MOSBENCH 测试应用##

为了强调内核，本文选择两类的应用：
>1. 之前的工作都显示其在Linux上**没有很好的扩展性**的应用
>2. 为**并行和内核集中**而设计的应用

本文使用内存里的tmpfs文件系统来模拟**无磁盘**的情形，以避免大多数应用因为磁盘写而产生的瓶颈。这些应用都起到了强调内核中那些在单核上运行花掉大多CPU时间的重要部分：

####1. Mail server####
Exim是一个mail server：用一个服务器来处理listens，并且为每个链接生成一个新进程，用来准备接受要发来的邮件，并且对他们做排序，归类，删除过期邮件，把信息记录到共享的日志文件中。每个链接进程会被唤醒两次来接受信息。在多用户高并发的情况下，Exim体现出高并行性，在单核上用了69%的内核时间，**强调了进程创建以及小文件的创建和删除**。

####2. Object cache####
memcached是在内存中的k-v对存储常用来提高网页应用性能的。当一个memcached的服务器跑在多核上时，保护k-v哈希表的内部锁会成为它的瓶颈。为了避免，跑多个mamcached服务器，每个都有自己的端口，直接从服务器中查找，让服务器们能并行处理请求。当请求小时，用80%的内核时间在单核上处理包，**它着重强调网络栈**。

####3. Web server ####
将Apache服务器配置成一个实例在80端口监听，每个实例上有一个进程在单核上跑，每个进程有一个线程池来提供通信服务，一个线程用来接受将要到来的信息，其他的则处理这些信息。除了网络栈，由于它每来一个请求都会打开一个文件，这个配置**着重于文件系统，尤其是目录名的查找**。在单核上，其用掉60%的内核执行时间。

####4. Database ####
PostgreSQL不像本文其他负载，它能更大限度发挥内部共享数据结构和同步性的作用。他也**强调内核中很多共享资源**。它依赖于快照隔离（一种避免大多数读锁的并发控制方法）。其实在共享模式下，它中间的很多写操作只需要粗粒度的锁。所以在实际中，它**不仅因为内核而产生瓶颈，也因为自身的代码**。在只读负载下，它避免了大多数的瓶颈，单核时仅使用内核时间的1.5%，但是48核时激涨到82%。

####5. Parallel build ####
通过用gmake编译Linux 2.6.35-rc5 kernel来作为本文的benchmark。gmake会创建多于核数的进程，并且读写很多文件。占用76%系统时间。

####6. File indexer ####
pedsort是用来查询网页的。它首先从作业队列中取出输入文件，读每个文件并且对每个词译码。这一阶段是计算敏感的和文件系统敏感的。为了避免，把队列中的文件排好序。它在单核上运行时，仅使用1.9%的内核时间，在48核上上升到23%。

####7. MapReduce ####
Metis是多核单服务器MapRedue文件库。本文用它来生成反索引。这个负载分配大量的内存来记录临时表，**强调内核内存分配器和页错误处理**。单核时间3%，48核16%。

##内核优化##
根据阿姆达定律，串行部分会阻碍随核数增加而性能增加。列举常见的串行并相关的类型：
>1. 任务锁住一个共享的数据区域，增加核数的同时会增加等锁时间。
>2. 任务写一个共享区域是，会打破cache的连续性。
>3. 任务写共享内存区域时，增加核数会使cache命中率降低，颠簸严重。
>4. 任务们有可能竞争硬件资源例如内部核通信或DRAM接口，其他的核等资源而不计算。
>5. 有可能没那么多任务来给那么多核做，多增加核数多出不工作的核。

很多症状表明延迟都与cache缺失有关。每个core有一个cache时，当一个
core想要写缓存别的core已缓存的内容，则要将别的core里的缓存信息无效掉。类似等等。从片外读数据需要很长的时钟周期，所以共享易变的数据会比预期降低性能。

####多核包处理####
传输扩展：Linux简单地把出硬件队列的包放在当前的核上，对于要来的包，网卡提供一个接口来配置硬件使得在一个特定核上的具体队列里的包满足特定条件，如源IP地址和端口号。这种设置对长链接好而对短的不好。
本文通过修改accpet，使硬件能决定哪个核以及核上哪个线程会来处理即将到来的包。

####模糊计数器####
Linux使用共享的计数器在多核下会成为一个瓶颈，因为很多核会并发地去更新它。
本文解决：提出sloppy counter，